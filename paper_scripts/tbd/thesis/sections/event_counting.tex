\documentclass[../thesis.tex]{subfiles}

\input{../../common/preamble}

\begin{document}

\section{Event Processing}
\subsection{Building an Observed Dataset}

During a HEP experiment, large amount of collision events occur inside the detector. The original number of such events in a dataset is denoted by $\true{N}$.

When detected, some physical attributes of each event are measured, e.g., energy, momentum components, angles. Let each event \( x \in \mathbb{R}^k \equiv \{\phi^i\}\) be a point in \( k \)-dimensional feature space. Each dataset \(\mathbf{A} \in \mathbb{R}^{\true{N} \times k}\) consists of such events.

Due to limited detector efficiency and selection effects, not all events that occur inside the detector are observed. Let $\eta(x)$ be the probability with which an event is detected, and hence appears in the observed dataset.

We define the filtering process \(\detector(\eta, n)\) that stochastically removes events:
\[
\detector(\eta, n) := \{ x_i \in n \mid x_i \text{ is retained with probability } \eta(x_i) \}.
\]

The observed (filtered) dataset is then:
\[
\meas{A} = \detector(\eta, \dataset{A})
\]

with $|\reco{A}| = \meas{N}$, the observed number of events.

Our goal is to estimate \( \true{N} \) from the observed \( \meas{N} \), correcting for detector efficiency effects and propagating uncertainties associated with the efficiency estimation.

\subsection{Adding Binwise Nuisance Parameters}

Now expressing the efficiency functions as:

\begin{align*}
    \eta(x) &: \mathbb{R}^k \to [0,1] \equiv \prod_{i=1}^k \eta^i(\phi^i)
\end{align*}

with

\begin{align*}
    \eta^i(\phi^i) &: \mathbb{R} \to [0,1] \equiv e^{\nu^i}\theta^i(\phi^i)
\end{align*}

with $\theta^i$ representing our knowledge of the efficiency of each bin. This means, we allow for an efficiency function that varies from our understanding of it through usage of nuisance parameters $\nu^i$, that are, for the time being, unconstrained.

\subsection{Efficiency Compensation via Event Weights}

To reconstruct the statistics of the original datasets, we assign weights:

\[
\text{for } x_i \in \tilde{\mathbf{A}}, \quad w_i := \frac{1}{\eta(x_i)}
\]

This gives rise to the efficiency-compensated reconstructed datasets:

\[
\dot{\mathbf{A}} := \{ (x_i, w_i) \mid x_i \in \tilde{\mathbf{A}} \}
\]

The estimated total event counts become:
\[
\reco{N} = \sum_{x_i \in \meas{A}} w_i \approx \true{N}
\]

\subsection*{Proposition 1 (Unbiasedness of the weighted estimator).}
Let \(\{x_j\}_{j=1}^{\true{N}}\) be the set of true collected events, each detected independently with probability \(\eta(x_j)\). Then:
\[
\mathbb{E}\!\left[ \reco{N} \right] = \true{N}
\]
\emph{Proof.}
For a single event \(x_j\), the contribution to the sum is \(\frac{1}{\eta(x_j)}\) if detected and \(0\) otherwise. Its expectation is:
\[
\eta(x_j) \cdot \frac{1}{\eta(x_j)} + (1-\eta(x_j))\cdot 0 = 1.
\]
Summing over all \(\true{N}\) events yields the result. \(\square\)

\end{document}